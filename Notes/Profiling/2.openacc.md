## 11.2 OpenACC: The easiest way to run on your GPU

As might be expected with a pragma-based approach, there is a large payoff for a small effort. But first, you have to work through the initial slowdown of the code. Don’t despair! It is normal to encounter an initial slowdown on your journey to faster computations on a GPU.
Often the most difficult step is getting a working OpenACC compiler toolchain.
- we’ll use the nvc NVIDIA compiler, version 24.3 with CUDA version 12.3
- you can first get information on your system with the `nvaccelinfo` command. It also lets you know if your system and environment are in working order

```
olia@krylov100:~/Diplomatiki/cnn-cifar10_0$ nvaccelinfo 

CUDA Driver Version:           12020
NVRM version:                  NVIDIA UNIX x86_64 Kernel Module  535.171.04  Tue Mar 19 20:30:00 UTC 2024

Device Number:                 0
Device Name:                   Tesla V100-PCIE-32GB
Device Revision Number:        7.0
Global Memory Size:            34079899648
Number of Multiprocessors:     80
Concurrent Copy and Execution: Yes
Total Constant Memory:         65536
Total Shared Memory per Block: 49152
Registers per Block:           65536
Warp Size:                     32
Maximum Threads per Block:     1024
Maximum Block Dimensions:      1024, 1024, 64
Maximum Grid Dimensions:       2147483647 x 65535 x 65535
Maximum Memory Pitch:          2147483647B
Texture Alignment:             512B
Clock Rate:                    1380 MHz
Execution Timeout:             No
Integrated Device:             No
Can Map Host Memory:           Yes
Compute Mode:                  default
Concurrent Kernels:            Yes
ECC Enabled:                   Yes
Memory Clock Rate:             877 MHz
Memory Bus Width:              4096 bits
L2 Cache Size:                 6291456 bytes
Max Threads Per SMP:           2048
Async Engines:                 7
Unified Addressing:            Yes
Managed Memory:                Yes
Concurrent Managed Memory:     Yes
Preemption Supported:          Yes
Cooperative Launch:            Yes
Default Target:                cc70

```

suggested flags for OpenACC:
pgi
CFLAGS:= -g -O3 -c99 -alias=ansi -Mpreprocess -acc -Mcuda -Minfo=accel

nvc
CFLAGS:= -g -O3 -c99 -alias=ansi -Mpreprocess -acc -cuda -Minfo=accel

- `-f[no-]strict-aliasing` :
                    Enable optimizations based on a strict interpretation of the aliasing rules that apply to the language being compiled, such as type-based alias analysis.

    `-alias=ansi|traditional` :
                    Select optimizations based on type-based pointer alias rules (deprecated, use -f[no-]strict-aliasing instead)

    We also include the `-alias=ansi` flag to tell the compiler to be less concerned about pointer aliasing so that it can more freely generate parallel kernels. It is still a good idea to include the restrict attribute on arguments in your source code to tell the compiler that variables do not point to overlapping regions of memory.

- `-Mpreprocess`        Run preprocessor for assembly and Fortran files
- `-cuda`               Add CUDA include paths. Link with the CUDA runtime libraries. Please refer to -gpu for target specific options

the compiler macro `_OPENACC == yyyymm`

### Parallel compute regions

`kernels` pragma that gives the compiler freedom to auto-parallelize the code block. This code block can include larger sections of code with several loops.

`parallel loop` pragma that tells the compiler to generate code for the GPU or other accelerator device.

